{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26216, 39)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data from database\n",
    "database_filepath = \"../data/DisasterResponse.db\"\n",
    "engine = create_engine('sqlite:///' + database_filepath)\n",
    "table_name = os.path.basename(database_filepath).replace(\".db\",\"\") + \"_table\"\n",
    "df = pd.read_sql_table(table_name, engine)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>water</th>\n",
       "      <th>food</th>\n",
       "      <th>shelter</th>\n",
       "      <th>clothing</th>\n",
       "      <th>money</th>\n",
       "      <th>missing_people</th>\n",
       "      <th>refugees</th>\n",
       "      <th>death</th>\n",
       "      <th>other_aid</th>\n",
       "      <th>infrastructure_related</th>\n",
       "      <th>transport</th>\n",
       "      <th>buildings</th>\n",
       "      <th>electricity</th>\n",
       "      <th>tools</th>\n",
       "      <th>hospitals</th>\n",
       "      <th>shops</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Weather update - a cold front from Cuba that c...</td>\n",
       "      <td>Un front froid se retrouve sur Cuba ce matin. ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>Is the Hurricane over or is it not over</td>\n",
       "      <td>Cyclone nan fini osinon li pa fini</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message  \\\n",
       "0   2  Weather update - a cold front from Cuba that c...   \n",
       "1   7            Is the Hurricane over or is it not over   \n",
       "\n",
       "                                            original   genre  related  \\\n",
       "0  Un front froid se retrouve sur Cuba ce matin. ...  direct        1   \n",
       "1                 Cyclone nan fini osinon li pa fini  direct        1   \n",
       "\n",
       "   request  offer  aid_related  medical_help  medical_products  \\\n",
       "0        0      0            0             0                 0   \n",
       "1        0      0            1             0                 0   \n",
       "\n",
       "   search_and_rescue  security  military  water  food  shelter  clothing  \\\n",
       "0                  0         0         0      0     0        0         0   \n",
       "1                  0         0         0      0     0        0         0   \n",
       "\n",
       "   money  missing_people  refugees  death  other_aid  infrastructure_related  \\\n",
       "0      0               0         0      0          0                       0   \n",
       "1      0               0         0      0          1                       0   \n",
       "\n",
       "   transport  buildings  electricity  tools  hospitals  shops  aid_centers  \\\n",
       "0          0          0            0      0          0      0            0   \n",
       "1          0          0            0      0          0      0            0   \n",
       "\n",
       "   other_infrastructure  weather_related  floods  storm  fire  earthquake  \\\n",
       "0                     0                0       0      0     0           0   \n",
       "1                     0                1       0      1     0           0   \n",
       "\n",
       "   cold  other_weather  direct_report  \n",
       "0     0              0              0  \n",
       "1     0              0              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape (26216,), y shape (26216, 35)\n"
     ]
    }
   ],
   "source": [
    "# Extract X and y variables from the data for the modelling\n",
    "X = df['message']\n",
    "y = df.drop(['id', 'message', 'original', 'genre'], axis = 1)\n",
    "\n",
    "print(f'X shape {X.shape}, y shape {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Process and tokenize text for Natural Language Processing (NLP) tasks.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text string to be tokenized.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of processed and tokenized words from the input text.\n",
    "    \"\"\"\n",
    "    # Normalize text\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "    \n",
    "    # tokenize text\n",
    "    words = nltk.word_tokenize(text)\n",
    "    \n",
    "    # remove stop words\n",
    "    stopwords_ = nltk.corpus.stopwords.words(\"english\")\n",
    "    words = [word for word in words if word not in stopwords_]\n",
    "    \n",
    "    # extract root form of words\n",
    "    words = [nltk.stem.WordNetLemmatizer().lemmatize(word, pos='v') for word in words]\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 0: Basic Pipeline**\n",
    "\n",
    "Components:\n",
    "\n",
    "* `CountVectorizer` with a custom tokenizer.\n",
    "* `TfidfTransformer` to transform the vectorized text into TF-IDF features.\n",
    "* `MultiOutputClassifier` with `RandomForestClassifier` as the estimator.\n",
    "\n",
    "*Purpose: This model sets up a basic text classification pipeline using Random Forest for multi-output classification.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0 = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer = tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "pipeline_fitted = model_0.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['related' 'request' 'aid_related' 'food' 'direct_report']\n"
     ]
    }
   ],
   "source": [
    "random_message = [\"I am hungry, I don't have food to eat, I don't have house I don't have clothes I count on you thank you so much\"]\n",
    "test_output = model_0.predict(random_message)\n",
    "print(y_train.columns.values[(test_output.flatten()==1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evaluate_multioutput(actual, predicted, col_names):\n",
    "    \"\"\"\n",
    "    Evaluate a multi-output classification model using various metrics.\n",
    "\n",
    "    This function calculates accuracy, precision, recall, and F1 score for\n",
    "    each output label in a multi-output classification task. It then returns\n",
    "    these metrics in a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        actual (numpy.ndarray): Array of actual labels.\n",
    "        predicted (numpy.ndarray): Array of predicted labels.\n",
    "        col_names (list of str): List of column names corresponding to the\n",
    "        output labels.\n",
    "\n",
    "    Returns:\n",
    "        metrics_df (pd.DataFrame): DataFrame containing accuracy, precision,\n",
    "                                   recall, and F1 score for each output label.\n",
    "    \"\"\"\n",
    "    metrics = []\n",
    "    \n",
    "    # Calculate evaluation metrics for each set of labels\n",
    "    for i in range(len(col_names)):\n",
    "        accuracy = accuracy_score(actual[:, i], predicted[:, i])\n",
    "        precision = precision_score(actual[:, i], predicted[:, i], average='weighted')\n",
    "        recall = recall_score(actual[:, i], predicted[:, i], average='weighted')\n",
    "        f1 = f1_score(actual[:, i], predicted[:, i], average='weighted')\n",
    "        \n",
    "        metrics.append([accuracy, precision, recall, f1])\n",
    "    \n",
    "    # Create dataframe containing metrics\n",
    "    metrics = np.array(metrics)\n",
    "    metrics_df = pd.DataFrame(data = metrics, index = col_names, columns = ['Accuracy', 'Precision', 'Recall', 'F1'])\n",
    "      \n",
    "    return metrics_df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics for test set\n",
    "y_pred = model_0.predict(X_test)\n",
    "col_names = list(y.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Accuracy  Precision    Recall        F1\n",
      "related                 0.816601   0.807584  0.816601  0.801927\n",
      "request                 0.893500   0.887975  0.893500  0.881535\n",
      "offer                   0.994507   0.989045  0.994507  0.991768\n",
      "aid_related             0.775252   0.773804  0.775252  0.773920\n",
      "medical_help            0.921880   0.902609  0.921880  0.894080\n",
      "medical_products        0.951480   0.943527  0.951480  0.933416\n",
      "search_and_rescue       0.976198   0.965005  0.976198  0.964739\n",
      "security                0.980470   0.961321  0.980470  0.970801\n",
      "military                0.970095   0.959582  0.970095  0.959240\n",
      "water                   0.960787   0.958051  0.960787  0.953405\n",
      "food                    0.940800   0.936887  0.940800  0.935780\n",
      "shelter                 0.935917   0.931427  0.935917  0.923114\n",
      "clothing                0.987183   0.986380  0.987183  0.982358\n",
      "money                   0.977724   0.978220  0.977724  0.967289\n",
      "missing_people          0.989625   0.979657  0.989625  0.984616\n",
      "refugees                0.965212   0.956215  0.965212  0.949556\n",
      "death                   0.957736   0.948843  0.957736  0.943157\n",
      "other_aid               0.870156   0.830028  0.870156  0.817593\n",
      "infrastructure_related  0.934849   0.874219  0.934849  0.903518\n",
      "transport               0.958346   0.951822  0.958346  0.942272\n",
      "buildings               0.954532   0.948556  0.954532  0.938655\n",
      "electricity             0.981843   0.977770  0.981843  0.973954\n",
      "tools                   0.994660   0.989348  0.994660  0.991997\n",
      "hospitals               0.988709   0.977546  0.988709  0.983096\n",
      "shops                   0.995575   0.991170  0.995575  0.993368\n",
      "aid_centers             0.986573   0.973326  0.986573  0.979905\n",
      "other_infrastructure    0.958041   0.918415  0.958041  0.937810\n",
      "weather_related         0.882667   0.880224  0.882667  0.879066\n",
      "floods                  0.956515   0.954073  0.956515  0.951498\n",
      "storm                   0.942325   0.936738  0.942325  0.937435\n",
      "fire                    0.990540   0.987574  0.990540  0.986262\n",
      "earthquake              0.971620   0.970820  0.971620  0.971047\n",
      "cold                    0.982148   0.977174  0.982148  0.975879\n",
      "other_weather           0.947818   0.929776  0.947818  0.924849\n",
      "direct_report           0.859017   0.851906  0.859017  0.836806\n"
     ]
    }
   ],
   "source": [
    "evaluate_0 = get_evaluate_multioutput(np.array(y_test), y_pred, col_names)\n",
    "print(evaluate_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 1: Grid Search with Hyperparameter Tuning**\n",
    "\n",
    "Base Model: Uses the pipeline from Model 1.\n",
    "\n",
    "Parameters Tuned:\n",
    "\n",
    "* `vect__min_df`: Minimum document frequency (1 and 5).\n",
    "* `tfidf__use_idf`: Whether to use IDF in TF-IDF (True and False).\n",
    "* `clf__estimator__n_estimators`: Number of trees in the Random Forest (10 and 25).\n",
    "\n",
    "Technique: `GridSearchCV` is used to find the best combination of these hyperparameters based on the f1_micro score.\n",
    "\n",
    "*Purpose: This model aims to improve performance by tuning hyperparameters through cross-validation.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV 1/5; 1/8] START clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1\n",
      "[CV 1/5; 1/8] END clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1;, score=nan total time=  19.5s\n",
      "[CV 2/5; 1/8] START clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1\n",
      "[CV 2/5; 1/8] END clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1;, score=nan total time=  20.1s\n",
      "[CV 3/5; 1/8] START clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1\n",
      "[CV 3/5; 1/8] END clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1;, score=nan total time=  20.3s\n",
      "[CV 4/5; 1/8] START clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1\n",
      "[CV 4/5; 1/8] END clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1;, score=nan total time=  19.7s\n",
      "[CV 5/5; 1/8] START clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1\n",
      "[CV 5/5; 1/8] END clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1;, score=nan total time=  20.0s\n",
      "[CV 1/5; 2/8] START clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 1/5; 2/8] END clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5;, score=nan total time=  15.5s\n",
      "[CV 2/5; 2/8] START clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 2/5; 2/8] END clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5;, score=nan total time=  16.4s\n",
      "[CV 3/5; 2/8] START clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 3/5; 2/8] END clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5;, score=nan total time=  16.5s\n",
      "[CV 4/5; 2/8] START clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 4/5; 2/8] END clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5;, score=nan total time=  16.3s\n",
      "[CV 5/5; 2/8] START clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 5/5; 2/8] END clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5;, score=nan total time=  15.7s\n",
      "[CV 1/5; 3/8] START clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1\n",
      "[CV 1/5; 3/8] END clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1;, score=nan total time=  20.0s\n",
      "[CV 2/5; 3/8] START clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1\n",
      "[CV 2/5; 3/8] END clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1;, score=nan total time=  19.9s\n",
      "[CV 3/5; 3/8] START clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1\n",
      "[CV 3/5; 3/8] END clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1;, score=nan total time=  19.6s\n",
      "[CV 4/5; 3/8] START clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1\n",
      "[CV 4/5; 3/8] END clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1;, score=nan total time=  19.9s\n",
      "[CV 5/5; 3/8] START clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1\n",
      "[CV 5/5; 3/8] END clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1;, score=nan total time=  19.6s\n",
      "[CV 1/5; 4/8] START clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5\n",
      "[CV 1/5; 4/8] END clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5;, score=nan total time=  14.4s\n",
      "[CV 2/5; 4/8] START clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5\n",
      "[CV 2/5; 4/8] END clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5;, score=nan total time=  14.1s\n",
      "[CV 3/5; 4/8] START clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5\n",
      "[CV 3/5; 4/8] END clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5;, score=nan total time=  14.8s\n",
      "[CV 4/5; 4/8] START clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5\n",
      "[CV 4/5; 4/8] END clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5;, score=nan total time=  14.2s\n",
      "[CV 5/5; 4/8] START clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5\n",
      "[CV 5/5; 4/8] END clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5;, score=nan total time=  14.4s\n",
      "[CV 1/5; 5/8] START clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1\n",
      "[CV 1/5; 5/8] END clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1;, score=nan total time=  44.3s\n",
      "[CV 2/5; 5/8] START clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1\n",
      "[CV 2/5; 5/8] END clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1;, score=nan total time=  44.7s\n",
      "[CV 3/5; 5/8] START clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1\n",
      "[CV 3/5; 5/8] END clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1;, score=nan total time=  45.6s\n",
      "[CV 4/5; 5/8] START clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1\n",
      "[CV 4/5; 5/8] END clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1;, score=nan total time=  44.9s\n",
      "[CV 5/5; 5/8] START clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1\n",
      "[CV 5/5; 5/8] END clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1;, score=nan total time=  44.8s\n",
      "[CV 1/5; 6/8] START clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 1/5; 6/8] END clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5;, score=nan total time=  34.4s\n",
      "[CV 2/5; 6/8] START clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 2/5; 6/8] END clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5;, score=nan total time=  34.5s\n",
      "[CV 3/5; 6/8] START clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 3/5; 6/8] END clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5;, score=nan total time=  35.3s\n",
      "[CV 4/5; 6/8] START clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 4/5; 6/8] END clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5;, score=nan total time=  34.9s\n",
      "[CV 5/5; 6/8] START clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 5/5; 6/8] END clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5;, score=nan total time=  34.7s\n",
      "[CV 1/5; 7/8] START clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1\n",
      "[CV 1/5; 7/8] END clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1;, score=nan total time=  44.3s\n",
      "[CV 2/5; 7/8] START clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1\n",
      "[CV 2/5; 7/8] END clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1;, score=nan total time=  45.6s\n",
      "[CV 3/5; 7/8] START clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1\n",
      "[CV 3/5; 7/8] END clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1;, score=nan total time=  44.7s\n",
      "[CV 4/5; 7/8] START clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1\n",
      "[CV 4/5; 7/8] END clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1;, score=nan total time=  45.5s\n",
      "[CV 5/5; 7/8] START clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1\n",
      "[CV 5/5; 7/8] END clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1;, score=nan total time=  44.1s\n",
      "[CV 1/5; 8/8] START clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5\n",
      "[CV 1/5; 8/8] END clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5;, score=nan total time=  30.9s\n",
      "[CV 2/5; 8/8] START clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5\n",
      "[CV 2/5; 8/8] END clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5;, score=nan total time=  30.9s\n",
      "[CV 3/5; 8/8] START clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5\n",
      "[CV 3/5; 8/8] END clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5;, score=nan total time=  31.4s\n",
      "[CV 4/5; 8/8] START clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5\n",
      "[CV 4/5; 8/8] END clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5;, score=nan total time=  31.6s\n",
      "[CV 5/5; 8/8] START clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5\n",
      "[CV 5/5; 8/8] END clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5;, score=nan total time=  31.4s\n"
     ]
    }
   ],
   "source": [
    "parameters = {'vect__min_df': [1, 5],\n",
    "              'tfidf__use_idf':[True, False],\n",
    "              'clf__estimator__n_estimators':[10, 25]}\n",
    "\n",
    "\n",
    "cv = GridSearchCV(model_0, param_grid=parameters, scoring='f1_micro', verbose = 10)\n",
    "model_gs = cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__estimator__n_estimators': 10, 'tfidf__use_idf': True, 'vect__min_df': 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters for best mean test score\n",
    "model_gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best results (with regard to f1_micro score) were achieved using the following parameters:\n",
    "\n",
    "- Random Forest Classifier number of estimators = 10\n",
    "- TfidfTransformer use_idf = True\n",
    "- CountVectorizer minimum df = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Accuracy  Precision    Recall        F1\n",
      "related                 0.799207   0.790445  0.799207  0.791609\n",
      "request                 0.885108   0.877912  0.885108  0.870593\n",
      "offer                   0.994507   0.989045  0.994507  0.991768\n",
      "aid_related             0.745194   0.743742  0.745194  0.740052\n",
      "medical_help            0.920049   0.895534  0.920049  0.894569\n",
      "medical_products        0.949802   0.935845  0.949802  0.931667\n",
      "search_and_rescue       0.976503   0.971247  0.976503  0.965480\n",
      "security                0.980317   0.961318  0.980317  0.970725\n",
      "military                0.969484   0.958657  0.969484  0.960508\n",
      "water                   0.960330   0.955777  0.960330  0.954878\n",
      "food                    0.930577   0.925575  0.930577  0.921288\n",
      "shelter                 0.932560   0.926965  0.932560  0.917939\n",
      "clothing                0.986573   0.985290  0.986573  0.981066\n",
      "money                   0.977113   0.966336  0.977113  0.966102\n",
      "missing_people          0.989625   0.979657  0.989625  0.984616\n",
      "refugees                0.965822   0.955371  0.965822  0.953142\n",
      "death                   0.960635   0.953902  0.960635  0.949580\n",
      "other_aid               0.867714   0.818560  0.867714  0.819879\n",
      "infrastructure_related  0.934239   0.874181  0.934239  0.903213\n",
      "transport               0.958041   0.948990  0.958041  0.942517\n",
      "buildings               0.953616   0.944390  0.953616  0.938020\n",
      "electricity             0.981843   0.976976  0.981843  0.974209\n",
      "tools                   0.994660   0.989348  0.994660  0.991997\n",
      "hospitals               0.988709   0.977546  0.988709  0.983096\n",
      "shops                   0.995575   0.991170  0.995575  0.993368\n",
      "aid_centers             0.986421   0.973324  0.986421  0.979829\n",
      "other_infrastructure    0.957583   0.927922  0.957583  0.938165\n",
      "weather_related         0.863442   0.860527  0.863442  0.856943\n",
      "floods                  0.940189   0.935137  0.940189  0.927618\n",
      "storm                   0.931950   0.922541  0.931950  0.922333\n",
      "fire                    0.990235   0.980866  0.990235  0.985528\n",
      "earthquake              0.964754   0.963220  0.964754  0.963398\n",
      "cold                    0.982453   0.980140  0.982453  0.975420\n",
      "other_weather           0.946750   0.923992  0.946750  0.926778\n",
      "direct_report           0.844675   0.828988  0.844675  0.822123\n"
     ]
    }
   ],
   "source": [
    "y_pred_gs = model_gs.predict(X_test)\n",
    "\n",
    "evaluate_1 = get_evaluate_multioutput(np.array(y_test), y_pred_gs, col_names)\n",
    "\n",
    "print(evaluate_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.947169</td>\n",
       "      <td>0.936761</td>\n",
       "      <td>0.947169</td>\n",
       "      <td>0.935306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.051789</td>\n",
       "      <td>0.054517</td>\n",
       "      <td>0.051789</td>\n",
       "      <td>0.056039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.775252</td>\n",
       "      <td>0.773804</td>\n",
       "      <td>0.775252</td>\n",
       "      <td>0.773920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.938358</td>\n",
       "      <td>0.924095</td>\n",
       "      <td>0.938358</td>\n",
       "      <td>0.923982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.958346</td>\n",
       "      <td>0.954073</td>\n",
       "      <td>0.958346</td>\n",
       "      <td>0.949556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.981996</td>\n",
       "      <td>0.977360</td>\n",
       "      <td>0.981996</td>\n",
       "      <td>0.974916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.995575</td>\n",
       "      <td>0.991170</td>\n",
       "      <td>0.995575</td>\n",
       "      <td>0.993368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accuracy  Precision     Recall         F1\n",
       "count  35.000000  35.000000  35.000000  35.000000\n",
       "mean    0.947169   0.936761   0.947169   0.935306\n",
       "std     0.051789   0.054517   0.051789   0.056039\n",
       "min     0.775252   0.773804   0.775252   0.773920\n",
       "25%     0.938358   0.924095   0.938358   0.923982\n",
       "50%     0.958346   0.954073   0.958346   0.949556\n",
       "75%     0.981996   0.977360   0.981996   0.974916\n",
       "max     0.995575   0.991170   0.995575   0.993368"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get summary stats for first model\n",
    "evaluate_0.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.943036</td>\n",
       "      <td>0.931155</td>\n",
       "      <td>0.943036</td>\n",
       "      <td>0.931143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.057865</td>\n",
       "      <td>0.060601</td>\n",
       "      <td>0.057865</td>\n",
       "      <td>0.061321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.745194</td>\n",
       "      <td>0.743742</td>\n",
       "      <td>0.745194</td>\n",
       "      <td>0.740052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.932255</td>\n",
       "      <td>0.923267</td>\n",
       "      <td>0.932255</td>\n",
       "      <td>0.919613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.960330</td>\n",
       "      <td>0.953902</td>\n",
       "      <td>0.960330</td>\n",
       "      <td>0.949580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.982148</td>\n",
       "      <td>0.975150</td>\n",
       "      <td>0.982148</td>\n",
       "      <td>0.974815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.995575</td>\n",
       "      <td>0.991170</td>\n",
       "      <td>0.995575</td>\n",
       "      <td>0.993368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accuracy  Precision     Recall         F1\n",
       "count  35.000000  35.000000  35.000000  35.000000\n",
       "mean    0.943036   0.931155   0.943036   0.931143\n",
       "std     0.057865   0.060601   0.057865   0.061321\n",
       "min     0.745194   0.743742   0.745194   0.740052\n",
       "25%     0.932255   0.923267   0.932255   0.919613\n",
       "50%     0.960330   0.953902   0.960330   0.949580\n",
       "75%     0.982148   0.975150   0.982148   0.974815\n",
       "max     0.995575   0.991170   0.995575   0.993368"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get summary stats for second model\n",
    "evaluate_1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 2: Feature Union Pipeline**\n",
    "\n",
    "Components:\n",
    "\n",
    "* `FeatureUnion` to combine multiple feature extraction pipelines.\n",
    "* `text_pipeline` within `FeatureUnion` includes `CountVectorizer` and `TfidfTransformer`.\n",
    "* `MultiOutputClassifier` with `RandomForestClassifier` as the estimator.\n",
    "\n",
    "*Purpose: This model allows for more complex feature engineering by using `FeatureUnion` to potentially combine text features with other types of features in the future.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fu = Pipeline([\n",
    "        ('features', FeatureUnion([\n",
    "            ('text_pipeline', Pipeline([\n",
    "                ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "                ('tfidf', TfidfTransformer())\n",
    "            ])),\n",
    "        ])),\n",
    "\n",
    "        ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Union\n",
    "pipeline_fu = model_fu.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Accuracy  Precision    Recall        F1\n",
      "related                 0.816143   0.807180  0.816143  0.801476\n",
      "request                 0.894568   0.889607  0.894568  0.882489\n",
      "offer                   0.994507   0.989045  0.994507  0.991768\n",
      "aid_related             0.771437   0.769949  0.771437  0.770108\n",
      "medical_help            0.920049   0.895667  0.920049  0.890467\n",
      "medical_products        0.950565   0.942831  0.950565  0.930787\n",
      "search_and_rescue       0.977724   0.974186  0.977724  0.968778\n",
      "security                0.980470   0.961321  0.980470  0.970801\n",
      "military                0.971010   0.964368  0.971010  0.959588\n",
      "water                   0.961245   0.958359  0.961245  0.954277\n",
      "food                    0.945529   0.942237  0.945529  0.942062\n",
      "shelter                 0.935764   0.930693  0.935764  0.923301\n",
      "clothing                0.986421   0.983999  0.986421  0.980968\n",
      "money                   0.977418   0.972349  0.977418  0.966841\n",
      "missing_people          0.989625   0.979657  0.989625  0.984616\n",
      "refugees                0.964754   0.951237  0.964754  0.948472\n",
      "death                   0.957125   0.947802  0.957125  0.941495\n",
      "other_aid               0.871987   0.843024  0.871987  0.820920\n",
      "infrastructure_related  0.934849   0.874219  0.934849  0.903518\n",
      "transport               0.958651   0.950320  0.958651  0.943987\n",
      "buildings               0.953006   0.945556  0.953006  0.935321\n",
      "electricity             0.981691   0.976204  0.981691  0.973865\n",
      "tools                   0.994660   0.989348  0.994660  0.991997\n",
      "hospitals               0.988709   0.977546  0.988709  0.983096\n",
      "shops                   0.995575   0.991170  0.995575  0.993368\n",
      "aid_centers             0.986573   0.973326  0.986573  0.979905\n",
      "other_infrastructure    0.958041   0.918415  0.958041  0.937810\n",
      "weather_related         0.884193   0.881835  0.884193  0.880693\n",
      "floods                  0.954074   0.951461  0.954074  0.948123\n",
      "storm                   0.940494   0.934463  0.940494  0.935313\n",
      "fire                    0.990388   0.985822  0.990388  0.985900\n",
      "earthquake              0.970400   0.969489  0.970400  0.969729\n",
      "cold                    0.981843   0.979615  0.981843  0.973817\n",
      "other_weather           0.947666   0.928284  0.947666  0.924493\n",
      "direct_report           0.860085   0.853827  0.860085  0.837809\n"
     ]
    }
   ],
   "source": [
    "y_pred_fu = model_fu.predict(X_test)\n",
    "\n",
    "evaluate_3 = get_evaluate_multioutput(np.array(y_test), y_pred_fu, col_names)\n",
    "\n",
    "print(evaluate_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.947064</td>\n",
       "      <td>0.936697</td>\n",
       "      <td>0.947064</td>\n",
       "      <td>0.935085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.051967</td>\n",
       "      <td>0.054056</td>\n",
       "      <td>0.051967</td>\n",
       "      <td>0.056090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.771437</td>\n",
       "      <td>0.769949</td>\n",
       "      <td>0.771437</td>\n",
       "      <td>0.770108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.938129</td>\n",
       "      <td>0.923349</td>\n",
       "      <td>0.938129</td>\n",
       "      <td>0.923897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.958651</td>\n",
       "      <td>0.951237</td>\n",
       "      <td>0.958651</td>\n",
       "      <td>0.948123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.981767</td>\n",
       "      <td>0.975195</td>\n",
       "      <td>0.981767</td>\n",
       "      <td>0.973841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.995575</td>\n",
       "      <td>0.991170</td>\n",
       "      <td>0.995575</td>\n",
       "      <td>0.993368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accuracy  Precision     Recall         F1\n",
       "count  35.000000  35.000000  35.000000  35.000000\n",
       "mean    0.947064   0.936697   0.947064   0.935085\n",
       "std     0.051967   0.054056   0.051967   0.056090\n",
       "min     0.771437   0.769949   0.771437   0.770108\n",
       "25%     0.938129   0.923349   0.938129   0.923897\n",
       "50%     0.958651   0.951237   0.958651   0.948123\n",
       "75%     0.981767   0.975195   0.981767   0.973841\n",
       "max     0.995575   0.991170   0.995575   0.993368"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get summary stats for third model\n",
    "evaluate_3.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, Model 0 is a straightforward pipeline for text classification. Model 1 enhances this by performing hyperparameter tuning to optimize the model. Model 2 introduces a more flexible architecture, paving the way for incorporating additional feature sets beyond text.\n",
    "\n",
    "Based on the provided results, here's a detailed analysis to determine which model has the best performance:\n",
    "\n",
    "**Model 0: Basic Pipeline**\n",
    "\n",
    "* F1 Score Mean: 0.935306\n",
    "* Standard Deviation: 0.056039\n",
    "\n",
    "**Model 1: Grid Search with Hyperparameter Tuning**\n",
    "\n",
    "* F1 Score Mean: 0.931143\n",
    "* Standard Deviation: 0.061321\n",
    "\n",
    "**Model 2: Feature Union Pipeline**\n",
    "\n",
    "* F1 Score Mean: 0.935085\n",
    "* Standard Deviation: 0.056090\n",
    "  \n",
    "**Analysis**\n",
    "\n",
    "F1 Score Mean:\n",
    "\n",
    "* Model 0 has the highest mean F1 score (0.935306), closely followed by Model 2 (0.935085).\n",
    "* Model 1 has the lowest mean F1 score (0.931143).\n",
    "\n",
    "Standard Deviation:\n",
    "\n",
    "* Model 0 has a standard deviation of 0.056039.\n",
    "* Model 2 has a slightly higher standard deviation of 0.056090.\n",
    "* Model 1 has the highest standard deviation (0.061321), indicating more variability in performance.\n",
    "\n",
    "**Conclusion**\n",
    "\n",
    "* Best Performance: Model 0 has the best performance with the highest mean F1 score (0.935306) and a relatively low standard deviation (0.056039), indicating both strong and consistent performance.\n",
    "* Second Best: Model 2 is very close in performance to Model 0, with a nearly identical mean F1 score (0.935085) and a slightly higher standard deviation (0.056090).\n",
    "* Least Preferred: Model 1 has the lowest mean F1 score (0.931143) and the highest standard deviation (0.061321), making it the least preferred model in terms of both average performance and consistency.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have chosen **Model 1** as the best model for the following reasons:\n",
    "\n",
    "* Comparable Performance: The performance metrics are very similar across all\n",
    "  three models. **Model 1** achieves a mean F1 score of 0.931143 with a standard\n",
    "  deviation of 0.061321, which is very close to the scores of Model 1 (mean F1\n",
    "  score of 0.935306 and standard deviation of 0.056039) and Model 3 (mean F1\n",
    "  score of 0.935085 and standard deviation of 0.056090). This indicates that\n",
    "  **Model 1** performs at a similar level of accuracy and consistency as the other\n",
    "  models.\n",
    "* Grid Search Optimization: **Model 1** utilizes GridSearchCV for hyperparameter\n",
    "  tuning, which systematically searches for the best combination of\n",
    "  hyperparameters to optimize model performance. This thorough approach ensures\n",
    "  that the model is well-tuned and can potentially achieve better performance in\n",
    "  different scenarios. The use of grid search demonstrates a more rigorous and\n",
    "  comprehensive method for model optimization.\n",
    "  \n",
    "Given the similar performance across the models and the added advantage of grid\n",
    "search optimization, **Model 1** stands out as the most robust and well-tuned choice\n",
    "for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = model_gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle best model\n",
    "pickle.dump(best_model, open('../models/disaster_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train_classifier.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
